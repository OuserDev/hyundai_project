"""
ë¶„ì„ ë¦¬í¬íŠ¸ í˜ì´ì§€ - íŠ¹ì • ì‹¤í–‰ ê¸°ë¡ì˜ ìƒì„¸ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
ë‹¤ì¢…/ë‹¤ì¤‘ ì„œë²„ í™˜ê²½ì— ìµœì í™”ëœ ë¦¬íŒ©í† ë§ ë²„ì „ (ì‹¤ì§ˆì  ìƒíƒœ ë°˜ì˜)
"""
import streamlit as st
import os
import json
import pandas as pd
from datetime import datetime
import glob
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import base64

def load_timestamp_results(timestamp):
    """íŠ¹ì • íƒ€ì„ìŠ¤íƒ¬í”„ì˜ JSON ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    result_folder = f"playbooks/playbook_result_{timestamp}/results"
    
    if not os.path.exists(result_folder):
        return None, f"ê²°ê³¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_folder}"
    
    json_files = glob.glob(f"{result_folder}/*.json")
    if not json_files:
        # JSON íŒŒì¼ì´ ì—†ì„ ë•Œ ë¡œê·¸ íŒŒì¼ ì •ë³´ ì¶”ê°€ ì œê³µ
        log_file = f"logs/ansible_execute_log_{timestamp}.log"
        error_msg = f"JSON ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result_folder}"
        
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                
                # ë¡œê·¸ì—ì„œ ì˜¤ë¥˜ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
                error_lines = []
                failed_lines = []
                recap_started = False
                
                for line in log_content.split('\n'):
                    line_lower = line.lower()
                    
                    if "play recap" in line_lower:
                        recap_started = True
                        continue
                    
                    if any(keyword in line_lower for keyword in ['error', 'failed', 'fatal', 'unreachable']):
                        if recap_started and "failed=" in line_lower:
                            failed_lines.append(line.strip())
                        elif not recap_started:
                            error_lines.append(line.strip())
                
                detailed_info = {
                    'error_msg': error_msg,
                    'log_file': log_file,
                    'has_log': True,
                    'error_lines': error_lines[-10:] if error_lines else [],
                    'failed_summary': failed_lines,
                    'log_size': len(log_content),
                }
                
                return None, detailed_info
                
            except Exception as e:
                error_msg += f"\në¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"
        else:
            error_msg += f"\nê´€ë ¨ ë¡œê·¸ íŒŒì¼ë„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file}"
        
        return None, error_msg
        
    all_data = []
    file_info = []
    server_list = set()
    check_types = set()
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                filename = os.path.basename(json_file)
                file_info.append({
                    'filename': filename,
                    'path': json_file,
                    'size': os.path.getsize(json_file),
                    'data_type': type(data).__name__
                })
                
                # ë°ì´í„° ì •ê·œí™” ë° ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict):
                            server_list.add(item.get('hostname', 'Unknown'))
                            # íŒŒì¼ëª…ì—ì„œ ì ê²€ íƒ€ì… ì¶”ì¶œ
                            check_type = filename.split('_')[1:3]  # ì˜ˆ: 1_1_1
                            if len(check_type) >= 2:
                                check_types.add('_'.join(check_type))
                    all_data.extend(data)
                elif isinstance(data, dict):
                    server_list.add(data.get('hostname', 'Unknown'))
                    check_type = filename.split('_')[1:3]
                    if len(check_type) >= 2:
                        check_types.add('_'.join(check_type))
                    all_data.append(data)
                    
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ {json_file} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            continue
    
    return {
        'data': all_data,
        'file_info': file_info,
        'total_files': len(json_files),
        'loaded_files': len(file_info),
        'servers': list(server_list),
        'check_types': list(check_types)
    }, None

def create_security_improvement_analysis(df):
    """ë³´ì•ˆ ê°œì„  íš¨ê³¼ ë¶„ì„ (ignore í•­ëª© ë°˜ì˜)"""
    if df.empty:
        return None, None, None
        
    # ì‹¤ì§ˆì  ìƒíƒœê°€ ì—†ìœ¼ë©´ ìƒì„± (ignore ê³ ë ¤)
    if 'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ' not in df.columns:
        df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] = (
            (df['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] == False) | 
            (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))
        )
    
    # 1. ì›ë˜ë¶€í„° ì–‘í˜¸ (ì¡°ì¹˜ ë¶ˆí•„ìš”)
    originally_safe = df[
        (df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True) & 
        (df['ì¡°ì¹˜ ì—¬ë¶€'] == False)
    ]
    
    # 2. ì¡°ì¹˜ í›„ ì–‘í˜¸ (ì·¨ì•½ ë°œê²¬ â†’ ì¡°ì¹˜ ì™„ë£Œ)
    remediated_safe = df[
        (df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
        (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))
    ]
    
    # 3. ì¡°ì¹˜ ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨/ë¬´ì‹œë¨
    attempted_but_failed = df[
        (df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
        (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì‹¤íŒ¨|ì˜¤ë¥˜|ERROR|FAILED|ë¬´ì‹œ|ignore|ê±´ë„ˆë›°|skip", case=False, na=False))
    ]
    
    # 4. ì—¬ì „íˆ ì·¨ì•½ (ì¡°ì¹˜ ì•ˆë¨)
    still_vulnerable = df[
        (df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False) & 
        (df['ì¡°ì¹˜ ì—¬ë¶€'] == False)
    ]
    
    # í†µê³„ ë°ì´í„° ìƒì„± (4ê°œ ì¹´í…Œê³ ë¦¬)
    improvement_stats = pd.DataFrame({
        'í•­ëª©': ['ì›ë˜ë¶€í„° ì–‘í˜¸', 'ì¡°ì¹˜ í›„ ì–‘í˜¸', 'ì¡°ì¹˜ ì‹œë„(ì‹¤íŒ¨/ë¬´ì‹œ)', 'ì—¬ì „íˆ ì·¨ì•½'],
        'ê°œìˆ˜': [len(originally_safe), len(remediated_safe), len(attempted_but_failed), len(still_vulnerable)],
        'ë¹„ìœ¨(%)': [
            len(originally_safe) / len(df) * 100,
            len(remediated_safe) / len(df) * 100,
            len(attempted_but_failed) / len(df) * 100,
            len(still_vulnerable) / len(df) * 100
        ]
    })
    
    # íŒŒì´ ì°¨íŠ¸ ìƒì„± (4ê°œ ì¹´í…Œê³ ë¦¬)
    fig1 = px.pie(
        improvement_stats,
        values='ê°œìˆ˜',
        names='í•­ëª©',
        title="ë³´ì•ˆ ìƒíƒœ ë¶„í¬ (ì¡°ì¹˜ ì‹œë„ í¬í•¨)",
        color='í•­ëª©',  # ğŸ”§ ì´ ë¼ì¸ ì¶”ê°€
        color_discrete_map={
            'ì›ë˜ë¶€í„° ì–‘í˜¸': '#28a745',        # ë…¹ìƒ‰
            'ì¡°ì¹˜ í›„ ì–‘í˜¸': '#17a2b8',         # ì²­ë¡ìƒ‰  
            'ì¡°ì¹˜ ì‹œë„(ì‹¤íŒ¨/ë¬´ì‹œ)': '#ffc107', # ë…¸ë€ìƒ‰
            'ì—¬ì „íˆ ì·¨ì•½': '#dc3545'           # ë¹¨ê°„ìƒ‰
        }
    )
    
    # ì„œë²„ë³„ ê°œì„  íš¨ê³¼ ì°¨íŠ¸ (4ê°œ ì¹´í…Œê³ ë¦¬)
    server_improvement = df.groupby('í˜¸ìŠ¤íŠ¸').apply(lambda x: pd.Series({
        'ì›ë˜_ì–‘í˜¸': len(x[(x['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True) & (x['ì¡°ì¹˜ ì—¬ë¶€'] == False)]),
        'ì¡°ì¹˜_í›„_ì–‘í˜¸': len(x[(x['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                            (x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))]),
        'ì¡°ì¹˜_ì‹œë„_ì‹¤íŒ¨': len(x[(x['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                             (x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì‹¤íŒ¨|ì˜¤ë¥˜|ERROR|FAILED|ë¬´ì‹œ|ignore|ê±´ë„ˆë›°|skip", case=False, na=False))]),
        'ì—¬ì „íˆ_ì·¨ì•½': len(x[(x['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False) & (x['ì¡°ì¹˜ ì—¬ë¶€'] == False)])
    })).reset_index()
    
    fig2 = px.bar(
        server_improvement,
        x='í˜¸ìŠ¤íŠ¸',
        y=['ì›ë˜_ì–‘í˜¸', 'ì¡°ì¹˜_í›„_ì–‘í˜¸', 'ì¡°ì¹˜_ì‹œë„_ì‹¤íŒ¨', 'ì—¬ì „íˆ_ì·¨ì•½'],
        title="ì„œë²„ë³„ ë³´ì•ˆ ê°œì„  íš¨ê³¼ (ì¡°ì¹˜ ì‹œë„ í¬í•¨)",
        labels={'value': 'í•­ëª© ìˆ˜', 'variable': 'ìƒíƒœ'},
        color_discrete_map={
            'ì›ë˜_ì–‘í˜¸': '#28a745',
            'ì¡°ì¹˜_í›„_ì–‘ê³ ': '#17a2b8', 
            'ì¡°ì¹˜_ì‹œë„_ì‹¤íŒ¨': '#ffc107',
            'ì—¬ì „íˆ_ì·¨ì•½': '#dc3545'
        }
    )
    fig2.update_layout(height=400)
    
    return fig1, fig2, {
        'originally_safe': originally_safe,
        'remediated_safe': remediated_safe,
        'attempted_but_failed': attempted_but_failed,
        'still_vulnerable': still_vulnerable,
        'stats': improvement_stats
    }
    
def create_failure_analysis(df):
    """ì‹¤íŒ¨í•œ ì‘ì—…ë“¤ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (ignore í¬í•¨)"""
    if df.empty:
        return None, None, None
    
    # ignoreëœ í•­ëª©ë“¤ê³¼ ì‹¤íŒ¨í•œ í•­ëª©ë“¤ ëª¨ë‘ í¬í•¨
    failed_items = df[
        (df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
        (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì‹¤íŒ¨|ì˜¤ë¥˜|ERROR|FAILED|ë¬´ì‹œ|ignore|ê±´ë„ˆë›°|skip", case=False, na=False))
    ]
    
    if len(failed_items) == 0:
        return None, None, {"message": "ì‹¤íŒ¨í•˜ê±°ë‚˜ ë¬´ì‹œëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤."}
    
    # ì‹¤íŒ¨ ìœ í˜• ì¬ë¶„ë¥˜
    def categorize_failure_type(result):
        result_lower = str(result).lower()
        if any(word in result_lower for word in ['ë¬´ì‹œ', 'ignore', 'ignored']):
            return 'Ignored (ë¬´ì‹œë¨)'
        elif any(word in result_lower for word in ['ê±´ë„ˆë›°', 'skip', 'skipped']):
            return 'Skipped (ê±´ë„ˆëœ€)'
        elif any(word in result_lower for word in ['ì‹¤íŒ¨', 'failed', 'error']):
            return 'Failed (ì‹¤íŒ¨)'
        else:
            return 'Other (ê¸°íƒ€)'
    
    failed_items_copy = failed_items.copy()
    failed_items_copy['ì‹¤íŒ¨_ìœ í˜•'] = failed_items_copy['ì¡°ì¹˜ ê²°ê³¼'].apply(categorize_failure_type)
    
    # 1. ì‹¤íŒ¨ ìœ í˜•ë³„ ë¶„ë¥˜
    failure_types = failed_items_copy.groupby('ì‹¤íŒ¨_ìœ í˜•').size().reset_index(name='count')
    
    fig1 = px.pie(
        failure_types,
        values='count',
        names='ì‹¤íŒ¨_ìœ í˜•',
        title="ì‹¤í–‰ ë¬¸ì œ ìœ í˜•ë³„ ë¶„í¬ (ì‹¤íŒ¨/ë¬´ì‹œ/ê±´ë„ˆëœ€)",
        color_discrete_map={
            'Failed (ì‹¤íŒ¨)': '#ff4444',
            'Ignored (ë¬´ì‹œë¨)': '#ff8800', 
            'Skipped (ê±´ë„ˆëœ€)': '#ffcc00',
            'Other (ê¸°íƒ€)': '#888888'
        }
    )
        
    # 2. ì„œë²„ë³„ ì‹¤íŒ¨ í˜„í™©
    server_failures = failed_items.groupby('í˜¸ìŠ¤íŠ¸').agg({
        'ì‘ì—… ì„¤ëª…': 'count',
        'ì¡°ì¹˜ ê²°ê³¼': lambda x: list(x.unique())
    }).reset_index()
    server_failures.columns = ['ì„œë²„ëª…', 'ì‹¤íŒ¨_ê°œìˆ˜', 'ì‹¤íŒ¨_ìœ í˜•ë“¤']
    
    fig2 = px.bar(
        server_failures,
        x='ì„œë²„ëª…',
        y='ì‹¤íŒ¨_ê°œìˆ˜',
        title="ì„œë²„ë³„ ì‹¤íŒ¨í•œ ì‘ì—… ìˆ˜",
        color='ì‹¤íŒ¨_ê°œìˆ˜',
        color_continuous_scale='Reds'
    )
    fig2.update_layout(height=400)
    
    # 3. ì‹¤íŒ¨ ìƒì„¸ ë°ì´í„°
    failure_details = {
        'total_failures': len(failed_items),
        'affected_servers': len(failed_items['í˜¸ìŠ¤íŠ¸'].unique()),
        'failure_types': failure_types.to_dict('records'),
        'server_breakdown': server_failures.to_dict('records'),
        'detailed_failures': failed_items[['í˜¸ìŠ¤íŠ¸', 'ì‘ì—… ì„¤ëª…', 'ì¡°ì¹˜ ê²°ê³¼', 'ì·¨ì•½ ì‚¬ìœ ']].to_dict('records')
    }
    
    return fig1, fig2, failure_details

def create_unreachable_hosts_analysis(df, result_data):
    """ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ í˜¸ìŠ¤íŠ¸ ë¶„ì„"""
    # ëª¨ë“  ì„œë²„ vs ì‹¤ì œ ê²°ê³¼ê°€ ìˆëŠ” ì„œë²„ ë¹„êµ
    expected_servers = set(result_data.get('servers', []))
    actual_servers = set(df['í˜¸ìŠ¤íŠ¸'].unique()) if not df.empty else set()
    
    unreachable_servers = expected_servers - actual_servers
    
    if not unreachable_servers:
        return None, {"message": "ëª¨ë“  ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤."}
    
    unreachable_data = pd.DataFrame({
        'ì„œë²„ëª…': list(unreachable_servers),
        'ìƒíƒœ': ['ì ‘ê·¼ ë¶ˆê°€'] * len(unreachable_servers)
    })
    
    fig = px.bar(
        unreachable_data,
        x='ì„œë²„ëª…',
        y=[1] * len(unreachable_servers),
        title="ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ì„œë²„ ëª©ë¡",
        color_discrete_sequence=['#ff4444']
    )
    fig.update_layout(
        height=300,
        yaxis_title="ì„œë²„ ìˆ˜",
        showlegend=False
    )
    
    analysis_data = {
        'total_unreachable': len(unreachable_servers),
        'unreachable_servers': list(unreachable_servers),
        'reachable_servers': list(actual_servers),
        'success_rate': len(actual_servers) / len(expected_servers) * 100 if expected_servers else 0
    }
    
    return fig, analysis_data

def create_vulnerability_severity_chart(df):
    """ì·¨ì•½ì  ì‹¬ê°ë„ë³„ ì°¨íŠ¸ ìƒì„± (ì‹¤ì§ˆì  ìƒíƒœ ë°˜ì˜, ì¡°ì¹˜ í›„ ì–‘í˜¸ êµ¬ë¶„)"""
    if df.empty:
        return None
    
    # ì‹¤ì§ˆì  ìƒíƒœê°€ ì—†ìœ¼ë©´ ìƒì„±
    if 'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ' not in df.columns:
        df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] = (
            (df['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] == False) | 
            (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))
        )
    
    # 3ë‹¨ê³„ ìƒíƒœë¡œ ì¬ë¶„ë¥˜
    df_chart = df.copy()
    
    def categorize_status(row):
        if row['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False:
            return 'ì‹¤ì§ˆì  ì·¨ì•½'
        elif row['ì¡°ì¹˜ ì—¬ë¶€'] == True and 'ì¡°ì¹˜ ì™„ë£Œ' in str(row['ì¡°ì¹˜ ê²°ê³¼']):
            return 'ì¡°ì¹˜ í›„ ì–‘í˜¸'
        else:
            return 'ì›ë˜ë¶€í„° ì–‘í˜¸'
    
    df_chart['ìƒì„¸_ìƒíƒœ'] = df_chart.apply(categorize_status, axis=1)
    
    severity_counts = df_chart.groupby(['ìƒì„¸_ìƒíƒœ', 'ì§„ë‹¨ ê²°ê³¼']).size().reset_index(name='count')
    
    # ìƒ‰ìƒ ë§¤í•‘
    color_map = {
        'ì›ë˜ë¶€í„° ì–‘í˜¸': '#28a745',    # ë…¹ìƒ‰
        'ì¡°ì¹˜ í›„ ì–‘í˜¸': '#17a2b8',     # ì²­ë¡ìƒ‰
        'ì‹¤ì§ˆì  ì·¨ì•½': '#dc3545'       # ë¹¨ê°„ìƒ‰
    }
    
    fig = px.sunburst(
        severity_counts,
        path=['ìƒì„¸_ìƒíƒœ', 'ì§„ë‹¨ ê²°ê³¼'],
        values='count',
        title="ì·¨ì•½ì  ì‹¬ê°ë„ ë¶„ì„ (ì¡°ì¹˜ íš¨ê³¼ êµ¬ë¶„)",
        color='ìƒì„¸_ìƒíƒœ',
        color_discrete_map=color_map
    )
    return fig

def create_server_comparison_chart(df):
    """ì„œë²„ë³„ ë¹„êµ ì°¨íŠ¸ (ì‹¤ì§ˆì  ìƒíƒœ ë°˜ì˜)"""
    if df.empty:
        return None
    
    # ì‹¤ì§ˆì  ìƒíƒœê°€ ì—†ìœ¼ë©´ ìƒì„±
    if 'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ' not in df.columns:
        df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] = (
            (df['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] == False) | 
            (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))
        )
        
    # ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€ìœ¼ë¡œ ì„œë²„ë³„ í†µê³„ ê³„ì‚°
    server_stats = df.groupby('í˜¸ìŠ¤íŠ¸').agg({
        'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ': ['count', lambda x: (~x).sum()],  # ì „ì²´ ê°œìˆ˜, ì‹¤ì§ˆì  ì·¨ì•½ ê°œìˆ˜
        'ì¡°ì¹˜ ì—¬ë¶€': 'sum'
    }).round(2)
    
    server_stats.columns = ['ì´_ì ê²€', 'ì‹¤ì§ˆì _ì·¨ì•½', 'ì¡°ì¹˜_ì™„ë£Œ']
    server_stats['ì‹¤ì§ˆì _ì–‘í˜¸'] = server_stats['ì´_ì ê²€'] - server_stats['ì‹¤ì§ˆì _ì·¨ì•½']
    server_stats = server_stats.reset_index()
    
    # ì„¸ë¶€ ë¶„ë¥˜ ì¶”ê°€
    server_details = df.groupby('í˜¸ìŠ¤íŠ¸').apply(lambda x: pd.Series({
        'ì›ë˜_ì–‘í˜¸': len(x[(x['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True) & (x['ì¡°ì¹˜ ì—¬ë¶€'] == False)]),
        'ì¡°ì¹˜_í›„_ì–‘í˜¸': len(x[(x['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                            (x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))]),
        'ì—¬ì „íˆ_ì·¨ì•½': len(x[x['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False])
    })).reset_index()
    
    # ì„œë²„ í†µê³„ì™€ ì„¸ë¶€ ë¶„ë¥˜ ë³‘í•©
    server_stats = server_stats.merge(server_details, on='í˜¸ìŠ¤íŠ¸')
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('ì„œë²„ë³„ ì‹¤ì§ˆì  ì·¨ì•½ì  í˜„í™©', 'ì¡°ì¹˜ ì™„ë£Œìœ¨', 'ì „ì²´ ë³´ì•ˆ ìƒíƒœ ë¶„í¬', 'ë³´ì•ˆ ê°œì„  íš¨ê³¼'),
        specs=[[{"type": "bar"}, {"type": "bar"}],
               [{"type": "pie"}, {"type": "bar"}]]
    )
    
    # ì„œë²„ë³„ ì‹¤ì§ˆì  ì·¨ì•½ì  í˜„í™©
    fig.add_trace(
        go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=server_stats['ì‹¤ì§ˆì _ì–‘í˜¸'], name='ì‹¤ì§ˆì  ì–‘í˜¸', marker_color='green'),
        row=1, col=1
    )
    fig.add_trace(
        go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=server_stats['ì‹¤ì§ˆì _ì·¨ì•½'], name='ì‹¤ì§ˆì  ì·¨ì•½', marker_color='red'),
        row=1, col=1
    )
    
    # ì¡°ì¹˜ ì™„ë£Œìœ¨ (ì „ì²´ ì ê²€ ëŒ€ë¹„ ì¡°ì¹˜ ì™„ë£Œëœ ë¹„ìœ¨)
    # remediated_safe ê³„ì‚°
    remediated_safe = df[(df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                        (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))]
    
    total_items_with_action = len(df[df['ì¡°ì¹˜ ì—¬ë¶€'] == True])  # ì¡°ì¹˜ê°€ ì‹œë„ëœ í•­ëª©
    if total_items_with_action > 0:
        completion_rate = len(remediated_safe) / total_items_with_action * 100
        fig.add_trace(
            go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=[completion_rate] * len(server_stats), name='ì¡°ì¹˜ ì™„ë£Œìœ¨(%)', marker_color='blue'),
            row=1, col=2
        )
    else:
        fig.add_trace(
            go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=[0] * len(server_stats), name='ì¡°ì¹˜ ì™„ë£Œìœ¨(%)', marker_color='blue'),
            row=1, col=2
        )
    
    # ì „ì²´ ë³´ì•ˆ ìƒíƒœ ë¶„í¬
    total_safe = server_stats['ì‹¤ì§ˆì _ì–‘í˜¸'].sum()
    total_vulnerable = server_stats['ì‹¤ì§ˆì _ì·¨ì•½'].sum()
    fig.add_trace(
        go.Pie(
            labels=['ì‹¤ì§ˆì  ì–‘í˜¸', 'ì‹¤ì§ˆì  ì·¨ì•½'], 
            values=[total_safe, total_vulnerable], 
            name="ì „ì²´ë¶„í¬",
            marker=dict(colors=['green', 'red'])  # ì–‘í˜¸=ë…¹ìƒ‰, ì·¨ì•½=ë¹¨ê°„ìƒ‰
        ),
        row=2, col=1
    )
    
    # ë³´ì•ˆ ê°œì„  íš¨ê³¼ (3ë‹¨ê³„ ë¶„ë¥˜)
    fig.add_trace(
        go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=server_stats['ì›ë˜_ì–‘í˜¸'], name='ì›ë˜ë¶€í„° ì–‘í˜¸', marker_color='#28a745'),
        row=2, col=2
    )
    fig.add_trace(
        go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=server_stats['ì¡°ì¹˜_í›„_ì–‘í˜¸'], name='ì¡°ì¹˜ í›„ ì–‘í˜¸', marker_color='#17a2b8'),
        row=2, col=2
    )
    fig.add_trace(
        go.Bar(x=server_stats['í˜¸ìŠ¤íŠ¸'], y=server_stats['ì—¬ì „íˆ_ì·¨ì•½'], name='ì—¬ì „íˆ ì·¨ì•½', marker_color='#dc3545'),
        row=2, col=2
    )
    
    fig.update_layout(height=800, showlegend=True, title_text="ì„œë²„ë³„ ì¢…í•© ë³´ì•ˆ ë¶„ì„ (ì‹¤ì§ˆì  ìƒíƒœ ë°˜ì˜)")
    return fig

def create_vulnerability_details_analysis(df):
    """ì·¨ì•½ì  ìƒì„¸ ë¶„ì„"""
    if df.empty:
        return None, None
        
    # ì·¨ì•½ì  ìœ í˜•ë³„ ë¶„ì„
    vulnerable_data = df[df['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] == True]
    
    if vulnerable_data.empty:
        return None, None
    
    # ì‘ì—… ì„¤ëª…ë³„ ì·¨ì•½ì  ë¶„í¬
    task_vuln = vulnerable_data['ì‘ì—… ì„¤ëª…'].value_counts()
    
    fig1 = px.bar(
        x=task_vuln.values, 
        y=task_vuln.index,
        orientation='h',
        title="ì·¨ì•½ì  ìœ í˜•ë³„ ë°œê²¬ ê±´ìˆ˜",
        labels={'x': 'ë°œê²¬ ê±´ìˆ˜', 'y': 'ì·¨ì•½ì  ìœ í˜•'},
        color=task_vuln.values,
        color_continuous_scale='Reds'
    )
    fig1.update_layout(height=400)
    
    # ì¡°ì¹˜ ìƒíƒœë³„ ë¶„ì„
    remediation_status = vulnerable_data.groupby(['ì¡°ì¹˜ ê²°ê³¼', 'í˜¸ìŠ¤íŠ¸']).size().reset_index(name='count')
    
    fig2 = px.bar(
        remediation_status,
        x='í˜¸ìŠ¤íŠ¸',
        y='count',
        color='ì¡°ì¹˜ ê²°ê³¼',
        title="ì„œë²„ë³„ ì¡°ì¹˜ ìƒíƒœ",
        barmode='stack'
    )
    fig2.update_layout(height=400)
    
    return fig1, fig2

def create_detailed_file_analysis(df):
    """ìƒì„¸ íŒŒì¼ ë¶„ì„ (SUID/SGID, ì†Œìœ ì ì—†ëŠ” íŒŒì¼ ë“±)"""
    if df.empty:
        return None
        
    # ì·¨ì•½ ì‚¬ìœ ì—ì„œ íŒŒì¼ ì •ë³´ê°€ ìˆëŠ” í•­ëª©ë“¤ ì¶”ì¶œ
    file_vulns = []
    
    for _, row in df.iterrows():
        if row['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] and 'ì·¨ì•½ ì‚¬ìœ ' in row and row['ì·¨ì•½ ì‚¬ìœ ']:
            reason = str(row['ì·¨ì•½ ì‚¬ìœ '])
            if 'SUID' in reason or 'SGID' in reason or 'ì†Œìœ ì' in reason or 'íŒŒì¼' in reason:
                file_vulns.append({
                    'ì„œë²„': row['í˜¸ìŠ¤íŠ¸'],
                    'ì ê²€í•­ëª©': row['ì‘ì—… ì„¤ëª…'],
                    'ì‚¬ìœ ': reason[:100] + '...' if len(reason) > 100 else reason,
                    'ì¡°ì¹˜ìƒíƒœ': row['ì¡°ì¹˜ ê²°ê³¼'] if row['ì¡°ì¹˜ ê²°ê³¼'] else 'ë¯¸ì¡°ì¹˜'
                })
    
    if not file_vulns:
        return None
        
    file_df = pd.DataFrame(file_vulns)
    
    # ì„œë²„ë³„ íŒŒì¼ ì·¨ì•½ì  í˜„í™©
    fig = px.treemap(
        file_df,
        path=['ì„œë²„', 'ì ê²€í•­ëª©', 'ì¡°ì¹˜ìƒíƒœ'],
        title="ì„œë²„ë³„ íŒŒì¼ ì·¨ì•½ì  ìƒì„¸ í˜„í™©",
        color='ì¡°ì¹˜ìƒíƒœ',
        color_discrete_map={
            'ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”': 'red',
            'ë¯¸ì¡°ì¹˜': 'orange',
            'ì¡°ì¹˜ì™„ë£Œ': 'green'
        }
    )
    fig.update_layout(height=500)
    
    return fig

def create_execution_timeline(timestamp):
    """ì‹¤í–‰ íƒ€ì„ë¼ì¸ ë¶„ì„ (ì˜¬ë°”ë¥¸ ë‚ ì§œ ì‹œê°„ í‘œì‹œ)"""
    log_file = f"logs/ansible_execute_log_{timestamp}.log"
    
    if not os.path.exists(log_file):
        return None
        
    try:
        # timestampì—ì„œ ì‹¤í–‰ ë‚ ì§œ ì¶”ì¶œ (ì˜ˆ: 20250620_141836)
        execution_date = datetime.strptime(timestamp, "%Y%m%d_%H%M%S").date()
        
        with open(log_file, 'r', encoding='utf-8') as f:
            log_content = f.read()
        
        # ë¡œê·¸ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
        timeline_events = []
        for line in log_content.split('\n'):
            if '[' in line and ']' in line:
                try:
                    time_part = line.split('[')[1].split(']')[0]
                    event_part = line.split(']')[1].strip()
                    
                    if 'TASK' in event_part or 'PLAY' in event_part:
                        # HH:MM:SS í˜•ì‹ì„ ì‹¤ì œ datetimeìœ¼ë¡œ ë³€í™˜
                        hour, minute, second = map(int, time_part.split(':'))
                        event_datetime = datetime.combine(execution_date, datetime.min.time().replace(
                            hour=hour, minute=minute, second=second
                        ))
                        
                        timeline_events.append({
                            'start_time': event_datetime,
                            'end_time': event_datetime + pd.Timedelta(seconds=30),  # 30ì´ˆ ì§€ì†ìœ¼ë¡œ ê°€ì •
                            'event': event_part[:50] + '...' if len(event_part) > 50 else event_part,
                            'type': 'TASK' if 'TASK' in event_part else 'PLAY'
                        })
                except:
                    continue
        
        if timeline_events:
            timeline_df = pd.DataFrame(timeline_events)
            
            # Gantt ì°¨íŠ¸ ìŠ¤íƒ€ì¼ì˜ íƒ€ì„ë¼ì¸
            fig = px.timeline(
                timeline_df,
                x_start="start_time",
                x_end="end_time", 
                y="event",
                color="type",
                title=f"Ansible ì‹¤í–‰ íƒ€ì„ë¼ì¸ ({execution_date.strftime('%Y-%m-%d')})",
                color_discrete_map={
                    'TASK': '#1f77b4',
                    'PLAY': '#ff7f0e'
                }
            )
            
            # xì¶• ì‹œê°„ í˜•ì‹ ê°œì„ 
            fig.update_xaxes(
                title="ì‹¤í–‰ ì‹œê°„",
                tickformat="%H:%M:%S"
            )
            fig.update_yaxes(title="ì‹¤í–‰ í•­ëª©")
            fig.update_layout(height=600, showlegend=True)
            return fig
            
    except Exception as e:
        st.error(f"íƒ€ì„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    return None

def calculate_execution_time(timestamp):
    """ë¡œê·¸ì—ì„œ ì‹¤í–‰ ì‹œê°„ì„ ê³„ì‚°"""
    log_file = f"logs/ansible_execute_log_{timestamp}.log"
    
    if not os.path.exists(log_file):
        return None
        
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            log_content = f.read()
        
        lines = log_content.split('\n')
        start_time = None
        end_time = None
        
        # ì‹œì‘ ì‹œê°„ê³¼ ì¢…ë£Œ ì‹œê°„ ì°¾ê¸°
        for line in lines:
            if '[' in line and ']' in line:
                try:
                    time_part = line.split('[')[1].split(']')[0]
                    # ì²« ë²ˆì§¸ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì‹œì‘ ì‹œê°„ìœ¼ë¡œ
                    if start_time is None:
                        start_time = time_part
                    # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¢…ë£Œ ì‹œê°„ìœ¼ë¡œ ê³„ì† ì—…ë°ì´íŠ¸
                    end_time = time_part
                except:
                    continue
        
        if start_time and end_time:
            # ì‹œê°„ í˜•ì‹: HH:MM:SS
            start_h, start_m, start_s = map(int, start_time.split(':'))
            end_h, end_m, end_s = map(int, end_time.split(':'))
            
            start_seconds = start_h * 3600 + start_m * 60 + start_s
            end_seconds = end_h * 3600 + end_m * 60 + end_s
            
            # ë‚ ì§œê°€ ë°”ë€ ê²½ìš° ì²˜ë¦¬
            if end_seconds < start_seconds:
                end_seconds += 24 * 3600
            
            duration_seconds = end_seconds - start_seconds
            
            # ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            minutes = duration_seconds // 60
            seconds = duration_seconds % 60
            
            return f"{minutes}ë¶„ {seconds}ì´ˆ"
            
    except Exception as e:
        return None
    
    return None
    """ì‹¤í–‰ íƒ€ì„ë¼ì¸ ë¶„ì„"""
    log_file = f"logs/ansible_execute_log_{timestamp}.log"
    
    if not os.path.exists(log_file):
        return None
        
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            log_content = f.read()
        
        # ë¡œê·¸ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ
        timeline_events = []
        for line in log_content.split('\n'):
            if '[' in line and ']' in line:
                try:
                    time_part = line.split('[')[1].split(']')[0]
                    event_part = line.split(']')[1].strip()
                    
                    if 'TASK' in event_part or 'PLAY' in event_part:
                        timeline_events.append({
                            'time': time_part,
                            'event': event_part[:50] + '...' if len(event_part) > 50 else event_part,
                            'type': 'TASK' if 'TASK' in event_part else 'PLAY'
                        })
                except:
                    continue
        
        if timeline_events:
            timeline_df = pd.DataFrame(timeline_events)
            
            fig = px.timeline(
                timeline_df,
                x_start="time",
                x_end="time", 
                y="event",
                color="type",
                title="Ansible ì‹¤í–‰ íƒ€ì„ë¼ì¸"
            )
            fig.update_layout(height=600)
            return fig
            
    except Exception as e:
        st.error(f"íƒ€ì„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    return None

def get_log_content(timestamp):
    """ë¡œê·¸ íŒŒì¼ ë‚´ìš©ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ (ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì—†ì´)"""
    log_file = f"logs/ansible_execute_log_{timestamp}.log"
    
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            return None
    else:
        return None

def parse_single_result(data):
    """ë‹¨ì¼ ê²°ê³¼ ë°ì´í„° íŒŒì‹± (ê°œì„ ëœ ë²„ì „)"""
    # vulnerability_detailsì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
    vuln_details = data.get("vulnerability_details", {})
    vulnerable_files = []
    
    # ë‹¤ì–‘í•œ í˜•íƒœì˜ ì·¨ì•½ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
    if "vulnerable_files_found" in vuln_details:
        vulnerable_files = vuln_details["vulnerable_files_found"]
    elif "file_list" in vuln_details:
        vulnerable_files = vuln_details["file_list"]
    elif "vulnerable_files" in vuln_details:
        vulnerable_files = vuln_details["vulnerable_files"]
    
    return pd.DataFrame([{
        "í˜¸ìŠ¤íŠ¸": data.get("hostname", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "ì§„ë‹¨ ê²°ê³¼": data.get("diagnosis_result", "ì•Œ ìˆ˜ ì—†ìŒ"),
        "ì „ì²´ ì·¨ì•½ ì—¬ë¶€": data.get("is_vulnerable", False),
        "ì¡°ì¹˜ ì—¬ë¶€": data.get("remediation_applied", False),
        "ì¡°ì¹˜ ê²°ê³¼": data.get("remediation_result", ""),
        "ì¡°ì¹˜ ì‹œê°„": data.get("remediation_timestamp", ""),
        "ì‘ì—… ì„¤ëª…": data.get("task_description", ""),
        "í”Œë ˆì´ë¶": data.get("playbook_name", ""),
        "ì·¨ì•½ ì‚¬ìœ ": vuln_details.get("reason", ""),
        "ì·¨ì•½ íŒŒì¼ ìˆ˜": len(vulnerable_files) if vulnerable_files else 0,
        "ê¶Œì¥ì‚¬í•­": vuln_details.get("recommendation", ""),
        "í˜„ì¬ ê¶Œí•œ": vuln_details.get("current_mode", ""),
        "í˜„ì¬ ì†Œìœ ì": vuln_details.get("current_owner", "")
    }])

def main(timestamp=None):
    """ë©”ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ í˜ì´ì§€"""
    
    if not timestamp:
        query_params = st.query_params
        timestamp = query_params.get("report", None)
    
    if not timestamp:
        st.error("âŒ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
    
    # í˜ì´ì§€ ì œëª©ê³¼ ì‹¤í–‰ ì‹œê°„
    col1, col2 = st.columns([3, 2])

    with col1:
        st.title("ğŸ”’ ë³´ì•ˆ ì ê²€ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    with col2:
        try:
            dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
            formatted_time = dt.strftime("%Y-%m-%d %H:%M:%S")
            st.markdown(f"<h4 style='text-align: right; margin-top: 20px; color: #1976d2;'>ğŸ“… {formatted_time}</h4>", 
                    unsafe_allow_html=True)
        except:
            st.markdown(f"<h4 style='text-align: right; margin-top: 20px; color: #1976d2;'>ğŸ“… {timestamp}</h4>", 
                    unsafe_allow_html=True)
    
    # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ë° ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸° ë²„íŠ¼
    st.markdown("---")
    
    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ğŸ“‚ ë¶„ì„ ê²°ê³¼ ë°ì´í„° ë¡œë”© ì¤‘..."):
        result_data, error = load_timestamp_results(timestamp)
        
        if error:
            if isinstance(error, dict):
                st.error(f"âŒ {error['error_msg']}")
                
                if error.get('has_log'):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"ğŸ“„ ë¡œê·¸ íŒŒì¼: `{error['log_file']}`") 
                    with col2:
                        st.info(f"ğŸ“Š ë¡œê·¸ í¬ê¸°: {error['log_size']:,} bytes")
                    
                    if error.get('failed_summary'):
                        st.subheader("âš ï¸ ì‹¤í–‰ ì‹¤íŒ¨ ìš”ì•½ (PLAY RECAP)")
                        for line in error['failed_summary']:
                            st.code(line)
                    
                    if error.get('error_lines'):
                        st.subheader("ğŸš¨ ì‹¤í–‰ ì¤‘ ë°œê²¬ëœ ì˜¤ë¥˜ë“¤ (ìµœê·¼ 10ê°œ)")
                        for line in error['error_lines']:
                            st.code(line, language="text")
                    
                    st.subheader("ğŸ“‹ ì „ì²´ ì‹¤í–‰ ë¡œê·¸")
                    try:
                        with open(error['log_file'], 'r', encoding='utf-8') as f:
                            full_log = f.read()
                        st.code(full_log, language="text")
                    except Exception as e:
                        st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            else:
                st.error(f"âŒ {error}")
            return            

        if not result_data or not result_data['data']:
            st.warning("ğŸ“­ ë¶„ì„ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    # ë°ì´í„° íŒŒì‹±
    try:
        all_dataframes = []
        
        for data_item in result_data['data']:
            if isinstance(data_item, dict):
                df = parse_single_result(data_item)
                all_dataframes.append(df)
        
        if not all_dataframes:
            st.warning("ğŸ“­ íŒŒì‹± ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        df = pd.concat(all_dataframes, ignore_index=True)
        
        # â­ ì‹¤ì§ˆì  ì–‘í˜¸ ìƒíƒœ ê³„ì‚° (ì¡°ì¹˜ ì™„ë£Œë„ ì–‘í˜¸ë¡œ ê°„ì£¼)
        df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] = (
            (df['ì „ì²´ ì·¨ì•½ ì—¬ë¶€'] == False) | 
            (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))
        )
        
        # ì„±ê³µ ë©”ì‹œì§€ì™€ ê¸°ë³¸ í†µê³„ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€)
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.success(f"âœ… **{len(df)}**ê°œ ì ê²€ í•­ëª©")
        with col2:
            st.info(f"ğŸ–¥ï¸ **{len(result_data['servers'])}**ê°œ ì„œë²„")
        with col3:
            st.warning(f"ğŸ“ **{result_data['total_files']}**ê°œ ê²°ê³¼ íŒŒì¼")
        with col4:
            # ì‹¤ì§ˆì  ì·¨ì•½ì  ìˆ˜ (ì¡°ì¹˜ ì™„ë£Œ ì œì™¸)
            actual_vulnerable_count = len(df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False])
            if actual_vulnerable_count > 0:
                st.error(f"âš ï¸ **{actual_vulnerable_count}**ê°œ ì‹¤ì§ˆì  ì·¨ì•½ì ")
            else:
                st.success("ğŸ›¡ï¸ **ëª¨ë“  ì·¨ì•½ì  í•´ê²°ë¨**")
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return
    
    # íƒ­ êµ¬ì„± (íŒŒì¼ ì‹œìŠ¤í…œ ë¶„ì„ ì œê±°)
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“Š ì¢…í•© ëŒ€ì‹œë³´ë“œ", 
        "ğŸ–¥ï¸ ì„œë²„ë³„ ë¶„ì„", 
        "ğŸ” ì·¨ì•½ì  ìƒì„¸", 
        "â±ï¸ ì‹¤í–‰ ë¶„ì„", 
        "ğŸ“„ ì›ë³¸ ë°ì´í„°"
    ])
    
    with tab1:
        # === ì¢…í•© ëŒ€ì‹œë³´ë“œ ===
        st.header("ğŸ“‹ ë³´ì•ˆ ì ê²€ ì¢…í•© í˜„í™©")
        
        # í•µì‹¬ ë©”íŠ¸ë¦­ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë‘ ìˆ˜ì •)
        total_checks = len(df)
        
        # ì‹¤ì§ˆì  ì·¨ì•½/ì–‘í˜¸ ìƒíƒœ ê³„ì‚°
        actual_vulnerable_items = len(df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False])
        actual_safe_items = len(df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True])
        
        remediation_needed = df[df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”", case=False, na=False)].shape[0]
        remediation_complete = df[df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì™„ë£Œ|ì„±ê³µ", case=False, na=False)].shape[0]
        
        # ê°œì„  íš¨ê³¼ ë¶„ì„ ì¶”ê°€ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€)
        originally_safe = df[(df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True) & (df['ì¡°ì¹˜ ì—¬ë¶€'] == False)]
        remediated_safe = df[(df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                           (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))]
        
        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("ğŸ” ì´ ì ê²€ í•­ëª©", total_checks)
        col2.metric("âš ï¸ ì‹¤ì§ˆì  ì·¨ì•½ì ", actual_vulnerable_items, delta=f"{(actual_vulnerable_items/total_checks*100):.1f}%")
        col3.metric("âœ… ì‹¤ì§ˆì  ì–‘í˜¸", actual_safe_items, delta=f"{(actual_safe_items/total_checks*100):.1f}%")
        col4.metric("ğŸ”§ ì¡°ì¹˜ í•„ìš”", remediation_needed)
        col5.metric("ğŸ›¡ï¸ ì¡°ì¹˜ ì™„ë£Œ", remediation_complete)
        
        # ë³´ì•ˆ ê°œì„  íš¨ê³¼ ë©”íŠ¸ë¦­ ì¶”ê°€
        st.markdown("### ğŸš€ ë³´ì•ˆ ê°œì„  íš¨ê³¼ ë¶„ì„")
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("ğŸŸ¢ ì›ë˜ë¶€í„° ì–‘í˜¸", len(originally_safe), 
                   help="ì²˜ìŒ ì ê²€ ì‹œë¶€í„° ë³´ì•ˆ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ë˜ì–´ ìˆë˜ í•­ëª©")
        col2.metric("ğŸ”„ ì¡°ì¹˜ í›„ ì–‘í˜¸", len(remediated_safe), 
                   help="ì·¨ì•½ì ì´ ë°œê²¬ë˜ì—ˆì§€ë§Œ Ansible ìë™ ì¡°ì¹˜ë¡œ ì–‘í˜¸í•´ì§„ í•­ëª©")
        
        if len(remediated_safe) > 0:
            # ì „ì²´ ë°œê²¬ëœ ë¬¸ì œ ì¤‘ì—ì„œ ìë™ í•´ê²°ëœ ë¹„ìœ¨
            total_issues_found = len(df[df['ì¡°ì¹˜ ì—¬ë¶€'] == True])  # ì¡°ì¹˜ê°€ ì‹œë„ëœ í•­ëª©ë“¤
            if total_issues_found > 0:
                improvement_rate = len(remediated_safe) / total_issues_found * 100
                col3.metric("ğŸ“ˆ ìë™ í•´ê²°ìœ¨", f"{improvement_rate:.1f}%",
                           help="ì¡°ì¹˜ê°€ ì‹œë„ëœ í•­ëª© ì¤‘ ì„±ê³µì ìœ¼ë¡œ í•´ê²°ëœ ë¹„ìœ¨")
            else:
                col3.metric("ğŸ“ˆ ìë™ í•´ê²°ìœ¨", "0%")
        else:
            col3.metric("ğŸ“ˆ ìë™ í•´ê²°ìœ¨", "0%")
            
        col4.metric("ğŸ¯ ì „ì²´ ë³´ì•ˆìœ¨", f"{(actual_safe_items/total_checks*100):.1f}%",
                   help="ì¡°ì¹˜ ì™„ë£Œ í¬í•¨í•œ ì‹¤ì§ˆì ìœ¼ë¡œ ì–‘í˜¸í•œ í•­ëª©ì˜ ë¹„ìœ¨")
        
        st.markdown(" ")
        
        # ë³´ì•ˆ ê°œì„  íš¨ê³¼ ì°¨íŠ¸
        fig_improvement1, fig_improvement2, improvement_data = create_security_improvement_analysis(df)
        if fig_improvement1 and fig_improvement2:
            col1, col2 = st.columns(2)
            with col1:
                st.plotly_chart(fig_improvement1, use_container_width=True)
            with col2:
                st.plotly_chart(fig_improvement2, use_container_width=True)
            
            # ê°œì„  íš¨ê³¼ ìƒì„¸ í…Œì´ë¸”
            with st.expander("ğŸ“Š ë³´ì•ˆ ê°œì„  íš¨ê³¼ ìƒì„¸ í†µê³„"):
                st.dataframe(improvement_data['stats'], use_container_width=True, hide_index=True)
                
                if len(improvement_data['remediated_safe']) > 0:
                    st.subheader("ğŸ”„ ìë™ ì¡°ì¹˜ë¡œ ê°œì„ ëœ í•­ëª©ë“¤")
                    remediated_display = improvement_data['remediated_safe'][['í˜¸ìŠ¤íŠ¸', 'ì‘ì—… ì„¤ëª…', 'ì¡°ì¹˜ ê²°ê³¼']].copy()
                    st.dataframe(remediated_display, use_container_width=True)
                else:
                    st.info("ìë™ ì¡°ì¹˜ë¡œ ê°œì„ ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì„œë²„ ë¹„êµ ì°¨íŠ¸ (ì‹¤ì§ˆì  ìƒíƒœê°€ í¬í•¨ëœ df ì „ë‹¬)
        fig_server_comparison = create_server_comparison_chart(df)
        if fig_server_comparison:
            st.plotly_chart(fig_server_comparison, use_container_width=True)
    
    with tab2:
        # === ì„œë²„ë³„ ë¶„ì„ ===
        st.header("ğŸ–¥ï¸ ì„œë²„ë³„ ìƒì„¸ ë¶„ì„")
        
        # ì„œë²„ ì„ íƒ
        selected_server = st.selectbox(
            "ë¶„ì„í•  ì„œë²„ ì„ íƒ:",
            options=['ì „ì²´'] + result_data['servers'],
            index=0
        )
        
        if selected_server == 'ì „ì²´':
            server_df = df
        else:
            server_df = df[df['í˜¸ìŠ¤íŠ¸'] == selected_server]
        
        if len(server_df) > 0:
            # ì„œë²„ë³„ í†µê³„ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€) - 2ì—´ë¡œ ë³€ê²½
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“Š ì ê²€ í˜„í™© (ì‹¤ì§ˆì  ìƒíƒœ)")
                server_stats = server_df.groupby('í˜¸ìŠ¤íŠ¸').agg({
                    'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ': ['count', lambda x: x.sum(), lambda x: (~x).sum()]
                }).round(2)
                server_stats.columns = ['ì´ì ê²€', 'ì‹¤ì§ˆì _ì–‘í˜¸', 'ì‹¤ì§ˆì _ì·¨ì•½']
                st.dataframe(server_stats, use_container_width=True)
            
            with col2:
                st.subheader("ğŸ”§ ì¡°ì¹˜ í˜„í™©")
                # ì¡°ì¹˜ í˜„í™©ì„ ë” ì„¸ë¶„í™”í•´ì„œ í‘œì‹œ
                remediation_detailed = server_df.groupby('í˜¸ìŠ¤íŠ¸').apply(lambda x: pd.Series({
                    'ì›ë˜ë¶€í„° ì–‘í˜¸': len(x[(x['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True) & (x['ì¡°ì¹˜ ì—¬ë¶€'] == False)]),
                    'ì¡°ì¹˜ ì™„ë£Œ': len(x[x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False)]),
                    'ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”': len(x[x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”", case=False, na=False)]),
                    'ì¡°ì¹˜ ë¶ˆí•„ìš”': len(x[x['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ë¶ˆí•„ìš”", case=False, na=False)])
                })).fillna(0).astype(int)
                
                st.dataframe(remediation_detailed, use_container_width=True)
            
            # ì ê²€ ìœ í˜•ì„ ë³„ë„ í–‰ìœ¼ë¡œ ì´ë™
            st.subheader("ğŸ“‹ ì ê²€ ìœ í˜• (ì „ì²´)")
            task_stats = server_df['ì‘ì—… ì„¤ëª…'].value_counts()  # head(10) ì œê±°
            
            # í‘œ í˜•íƒœë¡œ ë³€í™˜
            task_df = pd.DataFrame({
                'ì ê²€ í•­ëª©': task_stats.index,
                'ì ê²€ íšŸìˆ˜': task_stats.values
            })
            
            st.dataframe(task_df, use_container_width=True, hide_index=True)
            
            # ì„œë²„ë³„ ì·¨ì•½ì  íˆíŠ¸ë§µ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€)
            if len(result_data['servers']) > 1:
                st.subheader("ğŸ”¥ ì„œë²„-ì·¨ì•½ì  íˆíŠ¸ë§µ (ì‹¤ì§ˆì  ìƒíƒœ)")
                heatmap_data = df.pivot_table(
                    index='ì‘ì—… ì„¤ëª…', 
                    columns='í˜¸ìŠ¤íŠ¸', 
                    values='ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ', 
                    aggfunc=lambda x: (~x).sum(),  # ì‹¤ì§ˆì  ì·¨ì•½ì  ìˆ˜
                    fill_value=0
                )
                
                if not heatmap_data.empty:
                    fig_heatmap = px.imshow(
                        heatmap_data.values,
                        labels=dict(x="ì„œë²„", y="ì ê²€ í•­ëª©", color="ì‹¤ì§ˆì  ì·¨ì•½ì  ìˆ˜"),
                        x=heatmap_data.columns,
                        y=heatmap_data.index,
                        color_continuous_scale='Reds',
                        aspect="auto"
                    )
                    fig_heatmap.update_layout(height=600)
                    st.plotly_chart(fig_heatmap, use_container_width=True)
        else:
            st.info("ì„ íƒí•œ ì„œë²„ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab3:
        # === ì·¨ì•½ì  ìƒì„¸ ===
        st.header("ğŸ” ì·¨ì•½ì  ë° ì‹¤íŒ¨ ìƒì„¸ ë¶„ì„")
        
        # ì‹¤ì§ˆì ìœ¼ë¡œ ì·¨ì•½í•œ í•­ëª©ë§Œ í‘œì‹œ (ì¡°ì¹˜ ì™„ë£Œ ì œì™¸)
        vulnerable_df = df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False]
        
        if len(vulnerable_df) > 0:
            st.subheader(f"âš ï¸ ì‹¤ì§ˆì  ì·¨ì•½ì  ({len(vulnerable_df)}ê°œ)")
            st.info("ğŸ’¡ 'ì¡°ì¹˜ ì™„ë£Œ'ëœ í•­ëª©ì€ í•´ê²°ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸ë©ë‹ˆë‹¤.")
            
            # ì·¨ì•½ì  ìƒì„¸ ì°¨íŠ¸ (ì‹¤ì§ˆì  ì·¨ì•½ì  ê¸°ì¤€)
            fig1, fig2 = create_vulnerability_details_analysis(vulnerable_df)  # vulnerable_df ì‚¬ìš©
            if fig1:
                st.plotly_chart(fig1, use_container_width=True)
            if fig2:
                st.plotly_chart(fig2, use_container_width=True)
                
        else:
            st.success("ğŸ›¡ï¸ ëª¨ë“  ì·¨ì•½ì ì´ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.info("ì¼ë¶€ í•­ëª©ì€ 'ì¡°ì¹˜ ì™„ë£Œ' ìƒíƒœë¡œ ìë™ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì¡°ì¹˜ ì™„ë£Œëœ í•­ëª©ë“¤ë„ ë³„ë„ë¡œ í‘œì‹œ
        resolved_items = df[(df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                          (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì¡°ì¹˜ ì™„ë£Œ|ì™„ë£Œ|ì„±ê³µ", case=False, na=False))]
        
        if len(resolved_items) > 0:
            st.subheader(f"âœ… ìë™ í•´ê²°ëœ í•­ëª©ë“¤ ({len(resolved_items)}ê°œ)")
            
            with st.expander("ğŸ”§ Ansibleì´ ìë™ìœ¼ë¡œ í•´ê²°í•œ ì·¨ì•½ì ë“¤"):
                for idx, row in resolved_items.iterrows():
                    st.markdown(f"**{row['í˜¸ìŠ¤íŠ¸']}** - {row['ì‘ì—… ì„¤ëª…']}")
                    st.markdown(f"- ìƒíƒœ: {row['ì¡°ì¹˜ ê²°ê³¼']}")
                    if row['ì·¨ì•½ ì‚¬ìœ ']:
                        st.markdown(f"- ì›ì¸: {row['ì·¨ì•½ ì‚¬ìœ ']}")
                    st.markdown("---")
        
        # ì‹¤ì§ˆì  ì·¨ì•½ì ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ìƒì„¸ ë¶„ì„ í‘œì‹œ
        if len(vulnerable_df) > 0:
            # ì·¨ì•½ì  ìƒì„¸ í…Œì´ë¸”
            st.subheader("ğŸ“‹ ì‹¤ì§ˆì  ì·¨ì•½ì  ìƒì„¸ ëª©ë¡")
            
            # í•„í„°ë§ ì˜µì…˜
            col1, col2 = st.columns(2)
            with col1:
                filter_server = st.multiselect(
                    "ì„œë²„ í•„í„°:", 
                    options=vulnerable_df['í˜¸ìŠ¤íŠ¸'].unique(),
                    default=vulnerable_df['í˜¸ìŠ¤íŠ¸'].unique()
                )
            with col2:
                filter_remediation = st.selectbox(
                    "ì¡°ì¹˜ ìƒíƒœ í•„í„°:",
                    options=['ì „ì²´', 'ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”', 'ë¯¸ì¡°ì¹˜', 'ì‹¤íŒ¨'],
                    index=0
                )
            
            # í•„í„° ì ìš©
            filtered_vuln = vulnerable_df[vulnerable_df['í˜¸ìŠ¤íŠ¸'].isin(filter_server)]
            if filter_remediation != 'ì „ì²´':
                filtered_vuln = filtered_vuln[filtered_vuln['ì¡°ì¹˜ ê²°ê³¼'].str.contains(filter_remediation, case=False, na=False)]
            
            # ìƒì„¸ ì •ë³´ í‘œì‹œ
            for idx, row in filtered_vuln.iterrows():
                with st.expander(f"ğŸš¨ {row['í˜¸ìŠ¤íŠ¸']} - {row['ì‘ì—… ì„¤ëª…']}", expanded=False):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write(f"**ì§„ë‹¨ ê²°ê³¼:** {row['ì§„ë‹¨ ê²°ê³¼']}")
                        st.write(f"**í”Œë ˆì´ë¶:** {row['í”Œë ˆì´ë¶']}")
                        st.write(f"**ì¡°ì¹˜ ìƒíƒœ:** {row['ì¡°ì¹˜ ê²°ê³¼']}")
                        if row['ì·¨ì•½ íŒŒì¼ ìˆ˜'] > 0:
                            st.write(f"**ì˜í–¥ë°›ëŠ” íŒŒì¼:** {row['ì·¨ì•½ íŒŒì¼ ìˆ˜']}ê°œ")
                    
                    with col2:
                        if row['ì·¨ì•½ ì‚¬ìœ ']:
                            st.write("**ì·¨ì•½ ì‚¬ìœ :**")
                            st.info(row['ì·¨ì•½ ì‚¬ìœ '])
                        if row['ê¶Œì¥ì‚¬í•­']:
                            st.write("**ê¶Œì¥ì‚¬í•­:**")
                            st.success(row['ê¶Œì¥ì‚¬í•­'])
                    
                    # ì¶”ê°€ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­
                    if row['í˜„ì¬ ê¶Œí•œ'] or row['í˜„ì¬ ì†Œìœ ì']:
                        st.markdown("**ğŸ”§ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­:**")
                        tech_details = []
                        if row['í˜„ì¬ ê¶Œí•œ']:
                            tech_details.append(f"í˜„ì¬ ê¶Œí•œ: `{row['í˜„ì¬ ê¶Œí•œ']}`")
                        if row['í˜„ì¬ ì†Œìœ ì']:
                            tech_details.append(f"í˜„ì¬ ì†Œìœ ì: `{row['í˜„ì¬ ì†Œìœ ì']}`")
                        st.markdown(" | ".join(tech_details))
        
        # ğŸ†• ì‹¤íŒ¨ ë¶„ì„ ì„¹ì…˜ ì¶”ê°€
        st.markdown("---")
        st.subheader("âŒ ì‹¤í–‰ ì‹¤íŒ¨ ë¶„ì„")
        
        # ì‹¤íŒ¨í•œ ì‘ì—… ë¶„ì„
        fig_fail1, fig_fail2, failure_data = create_failure_analysis(df)
        
        if failure_data and 'message' in failure_data:
            st.success("âœ… " + failure_data['message'])
        elif failure_data:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ì‹¤íŒ¨ ì‘ì—…", failure_data['total_failures'])
            with col2:
                st.metric("ì˜í–¥ë°›ì€ ì„œë²„", failure_data['affected_servers'])
            with col3:
                failure_rate = failure_data['total_failures'] / len(df) * 100 if len(df) > 0 else 0
                st.metric("ì‹¤íŒ¨ìœ¨", f"{failure_rate:.1f}%")
            
            # ì‹¤íŒ¨ ì°¨íŠ¸
            if fig_fail1 and fig_fail2:
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(fig_fail1, use_container_width=True)
                with col2:
                    st.plotly_chart(fig_fail2, use_container_width=True)
            
            # ì‹¤íŒ¨ ìƒì„¸ ëª©ë¡
            with st.expander("ğŸ” ì‹¤íŒ¨í•œ ì‘ì—… ìƒì„¸ ëª©ë¡", expanded=False):
                for failure in failure_data['detailed_failures']:
                    st.markdown(f"**{failure['í˜¸ìŠ¤íŠ¸']}** - {failure['ì‘ì—… ì„¤ëª…']}")
                    st.markdown(f"- ì‹¤íŒ¨ ì‚¬ìœ : {failure['ì¡°ì¹˜ ê²°ê³¼']}")
                    if failure['ì·¨ì•½ ì‚¬ìœ ']:
                        st.markdown(f"- ì›ì¸: {failure['ì·¨ì•½ ì‚¬ìœ ']}")
                    st.markdown("---")
        
        # ğŸ†• ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ì„œë²„ ë¶„ì„
        st.subheader("ğŸ”Œ ì„œë²„ ì ‘ê·¼ì„± ë¶„ì„")
        
        fig_unreachable, unreachable_data = create_unreachable_hosts_analysis(df, result_data)
        
        if unreachable_data and 'message' in unreachable_data:
            st.success("âœ… " + unreachable_data['message'])
        elif unreachable_data:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì ‘ê·¼ ë¶ˆê°€ ì„œë²„", unreachable_data['total_unreachable'])
            with col2:
                st.metric("ì ‘ê·¼ ê°€ëŠ¥ ì„œë²„", len(unreachable_data['reachable_servers']))
            with col3:
                st.metric("ì ‘ê·¼ ì„±ê³µë¥ ", f"{unreachable_data['success_rate']:.1f}%")
            
            if fig_unreachable:
                st.plotly_chart(fig_unreachable, use_container_width=True)
            
            # ì ‘ê·¼ ë¶ˆê°€ ì„œë²„ ëª©ë¡
            if unreachable_data['unreachable_servers']:
                with st.expander("âš ï¸ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ì„œë²„ ëª©ë¡"):
                    for server in unreachable_data['unreachable_servers']:
                        st.markdown(f"- **{server}**: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ ë˜ëŠ” SSH ì ‘ê·¼ ë¶ˆê°€")
                        
                    st.info("ğŸ’¡ í•´ê²° ë°©ë²•: SSH í‚¤ ì„¤ì •, ë„¤íŠ¸ì›Œí¬ ì—°ê²°, ë°©í™”ë²½ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
                    
            # ì¡°ì¹˜ ì‹œë„í–ˆì§€ë§Œ ë¬´ì‹œëœ í•­ëª©ë“¤ ë³„ë„ í‘œì‹œ
            ignored_items = df[(df['ì¡°ì¹˜ ì—¬ë¶€'] == True) & 
                            (df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ë¬´ì‹œ|ignore", case=False, na=False))]

            if len(ignored_items) > 0:
                st.subheader(f"âš ï¸ ì¡°ì¹˜ ì‹œë„í–ˆì§€ë§Œ ë¬´ì‹œëœ í•­ëª©ë“¤ ({len(ignored_items)}ê°œ)")
                st.info("ğŸ’¡ ì´ í•­ëª©ë“¤ì€ ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì§€ë§Œ ignore_errors ì„¤ì •ìœ¼ë¡œ ì „ì²´ ì‹¤í–‰ì€ ê³„ì†ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                with st.expander("ğŸ”§ ë¬´ì‹œëœ í•­ëª©ë“¤ ìƒì„¸ë³´ê¸°"):
                    for idx, row in ignored_items.iterrows():
                        st.markdown(f"**{row['í˜¸ìŠ¤íŠ¸']}** - {row['ì‘ì—… ì„¤ëª…']}")
                        st.markdown(f"- ìƒíƒœ: {row['ì¡°ì¹˜ ê²°ê³¼']}")
                        if row['ì·¨ì•½ ì‚¬ìœ ']:
                            st.markdown(f"- ì›ì¸: {row['ì·¨ì•½ ì‚¬ìœ ']}")
                        st.markdown("---")
    
    with tab4:
        # === ì‹¤í–‰ ë¶„ì„ ===
        st.header("â±ï¸ Ansible ì‹¤í–‰ ë¶„ì„")
        
        # ì‹¤í–‰ íƒ€ì„ë¼ì¸
        fig_timeline = create_execution_timeline(timestamp)
        if fig_timeline:
            st.plotly_chart(fig_timeline, use_container_width=True)
        else:
            st.info("ì‹¤í–‰ íƒ€ì„ë¼ì¸ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì‹¤í–‰ í†µê³„ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€)
        st.subheader("ğŸ“Š ì‹¤í–‰ í†µê³„")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ì‹¤ì œ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = calculate_execution_time(timestamp)
            if execution_time:
                st.metric("â±ï¸ ì „ì²´ ì‹¤í–‰ ì‹œê°„", execution_time)
            
            st.metric("ğŸ“Š í‰ê·  ì„œë²„ë‹¹ ì ê²€", f"{len(df) / len(result_data['servers']) if result_data['servers'] else 0:.1f}ê°œ ì ê²€/ì„œë²„")
        
        # ğŸ†• ì‹¤íŒ¨ í˜„í™© ë©”íŠ¸ë¦­ ì¶”ê°€ (ignore í¬í•¨)
        attempted_failed_tasks = len(df[df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì‹¤íŒ¨|ì˜¤ë¥˜|ERROR|FAILED|ë¬´ì‹œ|ignore|ê±´ë„ˆë›°|skip", case=False, na=False)])
        ignored_tasks = len(df[df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ë¬´ì‹œ|ignore", case=False, na=False)])
        unreachable_count = len(set(result_data.get('servers', [])) - set(df['í˜¸ìŠ¤íŠ¸'].unique()))

        col5, col6 = st.columns(2)
        with col5:
            if attempted_failed_tasks > 0:
                st.warning(f"âš ï¸ **{attempted_failed_tasks}**ê°œ ì¡°ì¹˜ ë¬¸ì œ")
                if ignored_tasks > 0:
                    st.caption(f"â”” ê·¸ ì¤‘ {ignored_tasks}ê°œëŠ” ë¬´ì‹œë¨")
            else:
                st.success("âœ… **ëª¨ë“  ì¡°ì¹˜ ì„±ê³µ**")

        with col6:
            if unreachable_count > 0:
                st.warning(f"ğŸ”Œ **{unreachable_count}**ê°œ ì„œë²„ ì ‘ê·¼ë¶ˆê°€")
            else:
                st.success("ğŸŒ **ëª¨ë“  ì„œë²„ ì ‘ê·¼ê°€ëŠ¥**")
        
        with col2:
            # ì‹¤ì§ˆì  ì„±ê³µë¥ 
            success_rate = (len(df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == True]) / len(df) * 100) if len(df) > 0 else 0
            st.metric("âœ… ì‹¤ì§ˆì  ì„±ê³µë¥ ", f"{success_rate:.1f}%")
            
            automation_rate = (len(df[df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ì™„ë£Œ", case=False, na=False)]) / len(df) * 100) if len(df) > 0 else 0
            st.metric("ğŸ”§ ìë™ ì¡°ì¹˜ìœ¨", f"{automation_rate:.1f}%")
        
        with col3:
            st.metric("ğŸ–¥ï¸ ì ê²€ëœ ì„œë²„ ìˆ˜", len(result_data['servers']))
            st.metric("ğŸ“‹ ì ê²€ í•­ëª© ìœ í˜•", len(result_data['check_types']))
        
        # ì‹¤í–‰ ë¡œê·¸ ìš”ì•½
        st.subheader("ğŸ“‹ ì‹¤í–‰ ë¡œê·¸ ìš”ì•½")
        
        log_file = f"logs/ansible_execute_log_{timestamp}.log"
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                
                # ë¡œê·¸ í†µê³„ ì¶”ì¶œ
                total_lines = len(log_content.split('\n'))
                error_count = log_content.lower().count('error')
                warning_count = log_content.lower().count('warning')
                success_count = log_content.lower().count('success')
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("ì´ ë¡œê·¸ ë¼ì¸", total_lines)
                col2.metric("ì„±ê³µ ë©”ì‹œì§€", success_count)
                col3.metric("ê²½ê³  ë©”ì‹œì§€", warning_count)
                col4.metric("ì˜¤ë¥˜ ë©”ì‹œì§€", error_count)
                
                # ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸° (ë§ˆì§€ë§‰ 20ì¤„)
                log_lines = log_content.split('\n')
                preview_lines = log_lines[-20:] if len(log_lines) > 20 else log_lines
                
                with st.expander("ğŸ“„ ë¡œê·¸ ë¯¸ë¦¬ë³´ê¸° (ë§ˆì§€ë§‰ 20ì¤„)"):
                    st.code('\n'.join(preview_lines), language="text")
                    
            except Exception as e:
                st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        else:
            st.warning("ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab5:
        # === ì›ë³¸ ë°ì´í„° ===
        st.header("ğŸ“„ ì›ë³¸ ë°ì´í„° ë° ë‹¤ìš´ë¡œë“œ")
        
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.subheader("ğŸ“‚ ë¡œë“œëœ íŒŒì¼ ì •ë³´")
        
        if result_data['file_info']:
            file_info_df = pd.DataFrame(result_data['file_info'])
            
            # íŒŒì¼ í¬ê¸°ë¥¼ ì½ê¸° ì‰½ê²Œ ë³€í™˜
            def format_file_size(size_bytes):
                if size_bytes < 1024:
                    return f"{size_bytes} B"
                elif size_bytes < 1024**2:
                    return f"{size_bytes/1024:.1f} KB"
                else:
                    return f"{size_bytes/(1024**2):.1f} MB"
            
            file_info_df['readable_size'] = file_info_df['size'].apply(format_file_size)
            
            # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
            display_file_info = file_info_df[['filename', 'readable_size', 'data_type']].copy()
            display_file_info.columns = ['íŒŒì¼ëª…', 'í¬ê¸°', 'ë°ì´í„° íƒ€ì…']
            
            st.dataframe(display_file_info, use_container_width=True)
        else:
            st.info("íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ìš”ì•½ í†µê³„
        st.subheader("ğŸ“Š ë°ì´í„° ìš”ì•½")
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("ì´ ë°ì´í„° í•­ëª©", len(df))
        col2.metric("ì²˜ë¦¬ëœ ì„œë²„", len(result_data['servers']))
        col3.metric("ì ê²€ ìœ í˜•", len(result_data['check_types']))
        col4.metric("ê²°ê³¼ íŒŒì¼", result_data['total_files'])
        
        # ì „ì²´ ë°ì´í„° í…Œì´ë¸”
        st.subheader("ğŸ” ì„¸ë¶€ ë°ì´í„° ë³´ê¸°")
        
        # ì»¬ëŸ¼ ì„ íƒ ê¸°ëŠ¥
        available_columns = df.columns.tolist()
        selected_columns = st.multiselect(
            "í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ:",
            options=available_columns,
            default=['í˜¸ìŠ¤íŠ¸', 'ì‘ì—… ì„¤ëª…', 'ì§„ë‹¨ ê²°ê³¼', 'ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ', 'ì¡°ì¹˜ ê²°ê³¼']
        )
        
        if selected_columns:
            # í•„í„°ë§ ì˜µì…˜ (ì‹¤ì§ˆì  ìƒíƒœ ê¸°ì¤€)
            col1, col2 = st.columns(2)
            
            with col1:
                show_only_vulnerable = st.checkbox("ì‹¤ì§ˆì  ì·¨ì•½ì ë§Œ í‘œì‹œ", value=False)
            
            with col2:
                show_only_manual = st.checkbox("ìˆ˜ë™ ì¡°ì¹˜ í•„ìš” í•­ëª©ë§Œ í‘œì‹œ", value=False)
            
            # í•„í„° ì ìš©
            filtered_df = df.copy()
            
            if show_only_vulnerable:
                filtered_df = filtered_df[filtered_df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False]
            
            if show_only_manual:
                filtered_df = filtered_df[filtered_df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ìˆ˜ë™", case=False, na=False)]
            
            # ë°ì´í„° í‘œì‹œ
            if len(filtered_df) > 0:
                st.dataframe(filtered_df[selected_columns], use_container_width=True)
                
                # ìˆ˜ë™ ì¡°ì¹˜ í•„ìš” í•­ëª© ê°•ì¡° í‘œì‹œ
                manual_items = filtered_df[filtered_df['ì¡°ì¹˜ ê²°ê³¼'].str.contains("ìˆ˜ë™ ì¡°ì¹˜ í•„ìš”", case=False, na=False)]
                if len(manual_items) > 0:
                    st.warning(f"ğŸ”§ **ìˆ˜ë™ ì¡°ì¹˜ í•„ìš” í•­ëª©: {len(manual_items)}ê°œ**")
                    
                    with st.expander("ğŸš¨ ìˆ˜ë™ ì¡°ì¹˜ í•„ìš” í•­ëª© ìƒì„¸ë³´ê¸°"):
                        for idx, row in manual_items.iterrows():
                            st.markdown(f"**{row['í˜¸ìŠ¤íŠ¸']}** - {row['ì‘ì—… ì„¤ëª…']}")
                            if row['ì·¨ì•½ ì‚¬ìœ ']:
                                st.markdown(f"- ì‚¬ìœ : {row['ì·¨ì•½ ì‚¬ìœ ']}")
                            if row['ê¶Œì¥ì‚¬í•­']:
                                st.markdown(f"- ê¶Œì¥ì‚¬í•­: {row['ê¶Œì¥ì‚¬í•­']}")
                            st.markdown("---")
            else:
                st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("í‘œì‹œí•  ì»¬ëŸ¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
        st.subheader("â¬‡ï¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # CSV ë‹¤ìš´ë¡œë“œ
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“Š ì „ì²´ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ", 
                csv, 
                f"security_analysis_{timestamp}.csv", 
                "text/csv"
            )
        
        with col2:
            # ì‹¤ì§ˆì  ì·¨ì•½ì ë§Œ CSV ë‹¤ìš´ë¡œë“œ
            vulnerable_only = df[df['ì‹¤ì§ˆì _ì–‘í˜¸ìƒíƒœ'] == False]
            if len(vulnerable_only) > 0:
                vulnerable_csv = vulnerable_only.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    "âš ï¸ ì‹¤ì§ˆì  ì·¨ì•½ì  CSV ë‹¤ìš´",
                    vulnerable_csv,
                    f"actual_vulnerabilities_{timestamp}.csv",
                    "text/csv"
                )
            else:
                st.button("âš ï¸ ì‹¤ì§ˆì  ì·¨ì•½ì  CSV ë‹¤ìš´", disabled=True, help="ì‹¤ì§ˆì  ì·¨ì•½ì ì´ ì—†ìŠµë‹ˆë‹¤")
        
        with col3:
            # JSON ì›ë³¸ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result_data['data']:
                json_data = json.dumps(result_data['data'], ensure_ascii=False, indent=2)
                st.download_button(
                    "ğŸ“‹ ì›ë³¸ JSON ë‹¤ìš´ë¡œë“œ",
                    json_data,
                    f"raw_data_{timestamp}.json",
                    "application/json"
                )
                
        with col4:
            # ë¡œê·¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¶”ê°€
            log_content = get_log_content(timestamp)
            if log_content:
                st.download_button(
                    "ğŸ“¥ ì‹¤í–‰ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ",
                    log_content,
                    f"ansible_log_{timestamp}.log",
                    "text/plain",
                    key=f"download_log_{timestamp}"
                )
            else:
                st.button("ğŸ“¥ ì‹¤í–‰ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ", disabled=True, help="ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        # ë¡œê·¸ íŒŒì¼ ë‚´ìš© í‘œì‹œ
        st.subheader("ğŸ“‹ ì‹¤í–‰ ë¡œê·¸ ì „ì²´ë³´ê¸°")
        
        log_file = f"logs/ansible_execute_log_{timestamp}.log"
        if os.path.exists(log_file):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                
                # ë¡œê·¸ ê²€ìƒ‰ ê¸°ëŠ¥
                search_term = st.text_input("ğŸ” ë¡œê·¸ ê²€ìƒ‰:", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                
                if search_term:
                    # ê²€ìƒ‰ ê²°ê³¼ í•˜ì´ë¼ì´íŒ…
                    matching_lines = [line for line in log_content.split('\n') if search_term.lower() in line.lower()]
                    
                    st.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(matching_lines)}ê°œ ë¼ì¸ì—ì„œ '{search_term}' ë°œê²¬")
                    
                    if matching_lines:
                        st.markdown("**ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ 10ê°œ):**")
                        for line in matching_lines[:10]:
                            st.code(line.strip())
                        st.markdown("---")
                
                # ì „ì²´ ë¡œê·¸ í‘œì‹œ (ë°”ë¡œ í‘œì‹œ)
                st.code(log_content, language="text")
                
            except Exception as e:
                st.error(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
        else:
            st.warning(f"ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file}")

if __name__ == "__main__":
    main()